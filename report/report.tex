%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Wenneker Assignment
% LaTeX Template
% Version 2.0 (12/1/2019)
%
% This template originates from:
% http://www.LaTeXTemplates.com
%
% Authors:
% Vel (vel@LaTeXTemplates.com)
% Frits Wenneker
%
% License:
% CC BY-NC-SA 3.0 (http://creativecommons.org/licenses/by-nc-sa/3.0/)
% 
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%----------------------------------------------------------------------------------------
%	PACKAGES AND OTHER DOCUMENT CONFIGURATIONS
%----------------------------------------------------------------------------------------

\documentclass[11pt]{scrartcl} % Font size

\input{structure.tex} % Include the file specifying the document structure and custom commands

%----------------------------------------------------------------------------------------
%	TITLE SECTION
%----------------------------------------------------------------------------------------

\title{	
	\normalfont\normalsize
	\textsc{ČVUT, Fakulta informačních technologií}\\ % Your university, school and/or department name(s)
	\textsc{Vyhledávání na webu a v multimediálních databázích}\\
	\textsc{Letní semestr 2019/2020}\\
	\textsc{Závěrečná zpráva k projektu}\\
	\vspace{25pt} % Whitespace
	\rule{\linewidth}{0.5pt}\\ % Thin top horizontal rule
	\vspace{20pt} % Whitespace
	{\huge LSI vektorový model}\\ % The assignment title
	\vspace{12pt} % Whitespace
	\rule{\linewidth}{2pt}\\ % Thick bottom horizontal rule
	\vspace{12pt} % Whitespace
}

\author{\LARGE David Mašek a Kristýna Klesnilová} % Your name
\date{\normalsize\today} % Today's date (\today) or a custom date

\begin{document}

\maketitle % Print the title

\newpage

\tableofcontents

\newpage

\section{Popis projektu}

V tomto projektu implementujeme \emph{LSI vektorový model} sloužící k podobnostnímu vyhledávání v databázi anglických textových dokumentů. Tuto funkcionalitu následně vizualizujeme pomocí webového interface, který uživateli umožňuje procházet databázi článků na základě doporučování nejpodobnějších článků k právě čtenému.

\bigskip 

V experimentální části projektu jsme se dále zaměřili na:
\begin{itemize}
	\item Určení optimálního počtu konceptů
	\item Porovnání vlivu LSI na kvalitu výsledků vyhledávání s ohledem na výskyt synonym a homonym
	\item Porovnání průchodu pomocí LSI vektorového modelu se sekvenčním průchodem databáze
	\item Vliv různých vnitřních parametrů na výkon algoritmu (změna počtu extrahovaných termů, použití lemmatizace namísto stemmingu, odstranění číslovek při preprocesingu, použití jiného vzorce na výpočet vah termů...)
\end{itemize}

\bigskip 

Celý náš projekt je volně dostupný na: (Odkaz na gitlab?).

\section{Způsob řešení}

\subsection{Preprocesing dokumentů}

Jako první v naší aplikaci začínáme s preprocesingem dokumentů. Slova z jednotlivých dokumentů převedeme na malá písmena a odstraníme z nich nevýznamová slova a interpunkci. K identifikaci nevýznamových slov používáme seznam anglických nevýznamových slov. Jako parametr programu posíláme také, zda má z dokumentů odstranit i číslovky. Následně na zbylé termy aplikujeme \emph{stemming} či \emph{lemmatizaci}. Tím se snažíme slova, která mají stejný slovní základ, vyjádřit pouze jedním termem. Stemming to dělá pomocí algoritmu, kterým odsekává přípony a koncovky slova. Lemmatizace na to jde o něco chytřeji, podle kontextu slova se pokusí určit, o jaký slovní druh se jedná, a podle toho ho zkrátit.\footnote{nlp.stanford.edu/IR-book/html/htmledition/stemming-and-lemmatization-1.html} Porovnání jejich použití v programu se dále věnujeme v experimentální části.

\subsection{Výpočet vah termů}
V aplikaci vytváříme matici $M_w$, která má v řádcích jednotlivé termy a ve sloupcích jejich váhy v jednotlivých dokumentech.

\bigskip 

Začneme tím, že si vytvoříme matici počtu výskytů jednotlivých termů v jednotlivých dokumentech. Počet termů v této matici poté dále zredukujeme, abychom pracovali jen s těmi nejdůležitějšími. Funkci pro redukci termů posíláme následující parametry:
\begin{itemize}
	\item \emph{max\_df} - termy nacházející se ve více \% dokumentů, než udává číslo 100 * \emph{max\_df}, z matice odstraníme
	\item \emph{min\_df} - termy nacházející se v méně nebo stejně dokumentech, než udává číslo \emph{min\_df}, z matice odstraníme
	\item \emph{max\_terms} - maximální počet termů, které si v aplikaci necháme
	\item \emph{keep\_less\_freq} - udává, zda si při výběru \emph{max\_terms} termů nechat ty nejméně či nejvíce často zastoupené v dokumentech  
\end{itemize}

\bigskip 

Zkoumání vlivu změny jednotlivých parametrů na výsledek LSI se dále podrobněji věnujeme v experimentální části. V programu vždy nastavujeme \emph{min\_df} alespoň na 1, abychom odstranili termy nacházející se pouze v 1 dokumentu, které nám do LSI nepřidávají žádné užitečné informace. (pravda?)

\bigskip

Z této zredukované matice poté již spočteme matici $M_w$. Pro výpočet vah jednotlivých termů používáme metodiku \emph{tf-idf}. Váhu termu $t_i$ v dokumentu $d_j$ spočítáme podle vzorce:

\begin{align}
	\begin{split}
		w_{ij} = tf_{ij} \cdot idf_{ij}
	\end{split}					
\end{align}

kde $tf_{ij}$ reprezentuje normalizovanou četnost termu $t_i$ v dokumentu $d_j$ a spočítá se podle vzorce\footnote{https://en.wikipedia.org/wiki/Tf\%E2\%80\%93idf} :

\begin{align}
	\begin{split}
		tf_{ij} = \frac{f_{ij}}{nt_j}
	\end{split}					
\end{align}

kde $f_{ij}$ je četnost výskytu termu $t_i$ v dokumentu $d_j$, kterou normalizujeme číslem $nt_j$ vyjadřujícím celkový počet termů v dokumentu $d_j$. V přednášových slidech je použita normalizace jiná, $tf_{ij}$ se tam počítá podle vzorce:

\begin{align}
	\begin{split}
		tf_{ij} = \frac{f_{ij}}{max_i\{f_{ij}\}}
	\end{split}					
\end{align}

kde $max_i\{f_{ij}\}$ vrací nejvyšší četnost termu $t_i$ přes celou kolekci dokumentů. Tento způsob normalizace nám vrací spíše horší výsledky, jejich porovnáním se zabýváme v experimentální části.

$idf_{ij}$ reprezentuje převrácenou četnost $t_i$ ve všech dokumentech a spočítá se podle vzorce:

\begin{align}
	\begin{split}
		idf_{ij} = \log_2 (\frac{n}{df_i})
	\end{split}					
\end{align}

kde $n$ je celkový počet dokumentů a $df_i$ reprezentuje celkový počet dokumentů obsahujících term $t_i$.

\subsection{Implementace LSI}

Jakmile máme vytvořenou matici vah termů $M_w$, můžeme přistoupit k samotné implementaci LSI. Princip LSI spočívá v tom, že s pomocí \emph{singulárního rozkladu (SVD)} seskupíme tematicky podobné články do jednotlivých $k$ konceptů. Vlivem počtu konceptů na kvalitu výsledků se dále zabýváme v experimentální sekci.

\bigskip 

Singulární rozklad nám matici $M_w$ rozloží následovně:

\begin{align}
	\begin{split}
		M_w = U \cdot S \cdot V^T
	\end{split}					
\label{eq:svd}\
\end{align}

kde řádky matice $U$ jsou obrazy řádků matice $M_w$, sloupce matice $V$ jsou obrazy sloupců matice $M_w$ a matice $S$ obsahuje na diagonále \emph{singulární hodnoty (absolutní hodnoty vlastních čísel)} matice $M_w$ v sestupném pořadí. Z těchto matic získáme \emph{concept-by-document} matici $M_{cd}$ jako:

\begin{align}
	\begin{split}
		M_{cd} = S[k,k] \cdot V^T[k,:]
	\end{split}					
\end{align}

kde $S[k,k]$ značí prvních $k$ řádků a sloupců matice $S$ a $V^T[k,:]$ značí prvních $k$ řádků matice $V^T$, kde $k$ je počet konceptů. Nenásobíme tedy celou maticí $M_{cd}$, ale pouze její část podle počtu konceptů.

\bigskip

Matici projekce dotazu do prostoru konceptů $M_q$ pak získáme jako:

\begin{align}
	\begin{split}
		M_q = U^T[k,:]
	\end{split}					
\end{align}

kde $U^T[k,:]$ značí prvních $k$ řádků matice $U^T$.

\subsection{Vyhodnocení dotazu}

Při dotazu na nejpodobnější dokumenty k dokumentu $d_j$ převedeme dotaz do prostoru konceptů na vektor $V_c$ pomocí vzorce:

\begin{align}
	\begin{split}
		V_c = M_q \cdot M_{w_{:,j}}
	\end{split}					
\end{align}

kde $M_{w_{:,j}}$ značí j-tý sloupec matice $M_w$.

\bigskip

Vektor $V_c$ poté pomocí \emph{kosinové podobnosti} porovnáme se sloupcovými vektory matice $M_{cd}$. Indexy nejpodobnějších sloupcových vektorů matice $M_{cd}$ pak vrátíme jako indexy nejpodobnějších dokumentů k dokumentu dotazu $d_j$. Spolu s indexy vrátíme i samotnou hodnotu kosinové podobnosti.

\section{Implementace}

Celý projekt jsme programovali v jazyce \emph{Python}. Práci nám velmi usnadnila jeho knihovna \emph{NLTK}\footnote{https://www.nltk.org/} nabízející rozsáhlou funkcionalitu pro práci s přirozeným jazykem. Využili jsme například \emph{WordNetLemmatizer} pro lemmatizaci či \emph{SnowballStemmer} pro stemming. Dále jsme v programu hojně využívali Python knihovny \emph{pandas}\footnote{https://pandas.pydata.org/} a \emph{numpy}\footnote{https://numpy.org/}.

\bigskip

Ukládání dat v projektu řešíme přes CSV soubory, ke kterým přistupujeme přes pandas funkce. V jednom souboru máme uložený dataset nad kterým provádíme LSI. V dalších souborech pak máme uložené matice $M_w$, $M_{cd}$ a $M_q$, abychom je mohli cachovat a přepočítavat jen při změně LSI parametrů, které máme uložené v souboru \emph{server/lsa\_config.json}.

\bigskip

Procházení článků vizualizujeme v prohlížeči pomocí \emph{Flask}\footnote{https://flask.palletsprojects.com/en/1.1.x/} web serveru. Jako dataset v našem projektu používáme anglicky psané novinové články stažené z \emph{kaggle.com}\footnote{https://www.kaggle.com/snapcrack/all-the-news}. Dataset nepoužíváme celý, vybrali jsme z něj pouze 1000 článků.

\section{Příklad výstupu}

\begin{figure}[h] % [h] forces the figure to be output where it is defined in the code (it suppresses floating)
	\centering
	\includegraphics[width=0.7\columnwidth]{output.png}
	\caption{Příklad výstupu aplikace}
	\label{output}
\end{figure}

Na obrázku \ref{output} je vidět konkrétní vstup a výstup naší aplikace. Zobrazí se název článku dotazu, jméno jeho autora a také samotný text článku. Naše aplikace dále uživateli nabídne seznam 10 nejpodobnějších článků i s určenou kosinovou podobností v procentech. Je vidět, že aplikace vrací víceméně přesně to, co bychom čekali. K článku o tom, že firma SpaceX vypustila do vesmíru raketu, vrátí články týkající se firmy SpaceX či raket.

\section{Experimentální sekce}

\subsection{Určení optimálního počtu konceptů}

\begin{figure}[h] % [h] forces the figure to be output where it is defined in the code (it suppresses floating)
	\centering
	\includegraphics[width=0.7\columnwidth]{singular_values.png}
	\caption{Důležitost konceptů}
	\label{concepts}
\end{figure}

Vezmeme si singulární hodnoty, které nám vrátil singulární rozklad v rovnici \ref{eq:svd}. Vizualizujeme-li si v grafu \ref{concepts}, jak klesá poměr nejvyšší singulární hodnoty vůči zbylým singulárním hodnotám, vidíme z toho také, jak klesá důležitost konceptů v datasetu. Počet konceptů $k$ v naší aplikaci tedy podle tohoto grafu určíme jako 400.

\subsection{Porovnání vlivu LSI na kvalitu výsledků vyhledávání s ohledem na výskyt synonym a homonym}

Pro zjištění kvality výsledků vyhledávání s ohledem na výskyt synonym a homonym jsme si vytvořili testovací dataset 10 článků z anglické Wikipedie... TO BE CONTINUED!!!

\section{Diskuze}


\section{Závěr}

\end{document}
