%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Wenneker Assignment
% LaTeX Template
% Version 2.0 (12/1/2019)
%
% This template originates from:
% http://www.LaTeXTemplates.com
%
% Authors:
% Vel (vel@LaTeXTemplates.com)
% Frits Wenneker
%
% License:
% CC BY-NC-SA 3.0 (http://creativecommons.org/licenses/by-nc-sa/3.0/)
% 
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%----------------------------------------------------------------------------------------
%	PACKAGES AND OTHER DOCUMENT CONFIGURATIONS
%----------------------------------------------------------------------------------------

\documentclass[11pt]{scrartcl} % Font size

\input{structure.tex} % Include the file specifying the document structure and custom commands

%----------------------------------------------------------------------------------------
%	TITLE SECTION
%----------------------------------------------------------------------------------------

\title{	
	\normalfont\normalsize
	\textsc{ČVUT, Fakulta informačních technologií}\\ % Your university, school and/or department name(s)
	\textsc{Vyhledávání na webu a v multimediálních databázích}\\
	\textsc{Letní semestr 2019/2020}\\
	\textsc{Závěrečná zpráva k projektu}\\
	\vspace{25pt} % Whitespace
	\rule{\linewidth}{0.5pt}\\ % Thin top horizontal rule
	\vspace{20pt} % Whitespace
	{\huge LSI vektorový model}\\ % The assignment title
	\vspace{12pt} % Whitespace
	\rule{\linewidth}{2pt}\\ % Thick bottom horizontal rule
	\vspace{12pt} % Whitespace
}

\author{\LARGE David Mašek a Kristýna Klesnilová} % Your name
\date{\normalsize\today} % Today's date (\today) or a custom date

\begin{document}

\maketitle % Print the title

\newpage

\tableofcontents

\newpage

\section{Popis projektu}

V tomto projektu implementujeme LSI vektorový model sloužící k podobnostnímu vyhledávání v databázi anglických textových dokumentů. Tuto funkcionalitu následně vizualizujeme pomocí webového interface, který uživateli umožňuje procházet databázi článků na základě doporučování nejpodobnějších článků k právě čtenému.

\bigskip 

V experimentální části projektu jsme se dále zaměřili na:
\begin{itemize}
	\item Porovnání průchodu pomocí LSI vektorového modelu se sekvenčním průchodem databáze
	\item Porovnání vlivu LSI na kvalitu výsledků vyhledávání s ohledem na výskyt synonym a homonym
	\item Vliv různých vnitřních parametrů na výkon algoritmu (změna počtu konceptů, změna počtu extrahovaných termů, použití lemmatizace namísto stemmingu, odstranění číslovek při preprocesingu...)
	\item Jak se změní výsledky při použití jiného vzorce na výpočet vah termů
\end{itemize}

\bigskip 

Celý náš projekt je volně dostupný na: (Odkaz na gitlab?).

\section{Způsob řešení}

\subsection{Preprocesing dokumentů}

Jako první v naší aplikaci začínáme s preprocesingem dokumentů. Slova z jednotlivých dokumentů převedeme na malá písmena a odstraníme z nich nevýznamová slova a interpunkci. K identifikaci nevýznamových slov používáme seznam anglických nevýznamových slov. Jako parametr programu posíláme také, zda má z dokumentů odstranit i číslovky. Následně na zbylé termy aplikujeme \emph{stemming} či \emph{lemmatizaci}. Tím se snažíme slova, která mají stejný slovní základ, vyjádřit pouze jedním termem. Stemming to dělá pomocí algoritmu, kterým odsekává přípony a koncovky slova. Lemmatizace na to jde o něco chytřeji, podle kontextu slova se pokusí určit, o jaký slovní druh se jedná, a podle toho ho zkrátit.\footnote{nlp.stanford.edu/IR-book/html/htmledition/stemming-and-lemmatization-1.html}   Porovnání jejich použití v programu se dále věnujeme v experimentální části.

\subsection{Výpočet vah termů}
V aplikaci vytváříme matici $M_w$, která má v řádcích jednotlivé termy a ve sloupcích jejich váhy v jednotlivých dokumentech.

\bigskip 

Začneme tím, že si vytvoříme matici počtu výskytů jednotlivých termů v jednotlivých dokumentech. Počet termů v této matici poté dále zredukujeme, aby úloha byla výpočetně řešitelná v rozumném čase. Funkci pro redukci termů posíláme následující parametry:
\begin{itemize}
	\item \emph{max\_df} - termy nacházející se ve více \% dokumentů, než udává číslo 100 * \emph{max\_df}, z matice odstraníme
	\item \emph{min\_df} - termy nacházející se v méně nebo stejně dokumentech, než udává číslo \emph{min\_df}, z matice odstraníme
	\item \emph{max\_terms} - maximální počet termů, které si v aplikaci necháme
	\item \emph{keep\_less\_freq} - udává, zda si při výběru \emph{max\_terms} termů nechat ty nejméně či nejvíce často zastoupené v dokumentech  
\end{itemize}

\bigskip 

Zkoumání vlivu změny jednotlivých parametrů na výsledek LSI se dále podrobněji věnujeme v experimentální části. V programu vždy nastavujeme \emph{min\_df} alespoň na 1, abychom odstranili termy nacházející se pouze v 1 dokumentu, které nám do LSI nepřidávají žádné užitečné informace. (pravda?)

\bigskip

Z této zredukované matice poté již spočteme matici $M_w$. Pro výpočet vah jednotlivých termů používáme metodiku \emph{tf-idf}. Váhu termu $t_i$ v dokumentu $d_j$ spočítáme podle vzorce:

\begin{align}
	\begin{split}
		w_{ij} = tf_{ij} \cdot idf_{ij}
	\end{split}					
\end{align}

$tf_{ij}$ reprezentuje četnost termu $t_i$ v dokumentu $d_j$ a spočítá se podle vzorce\footnote{https://en.wikipedia.org/wiki/Tf\%E2\%80\%93idf} :

\begin{align}
	\begin{split}
		tf_{ij} = \frac{f_{ij}}{nt_j}
	\end{split}					
\end{align}

kde $f_ij$ je četnost výskytu termu $t_i$ v dokumentu $d_j$, kterou normalizujeme číslem $nt_j$ vyjadřujícím celkový počet termů v dokumentu $d_j$. V přednášových slidech je použita normalizace jiná, $tf{ij}$ se tam počítá podle vzorce:

\begin{align}
	\begin{split}
		tf_{ij} = \frac{f_{ij}}{max_i\{f_{ij}\}}
	\end{split}					
\end{align}

kde $max_i\{f_{ij}\}$ vrací nejvyšší četnost termu $t_i$ přes celou kolekci dokumentů. Tento způsob normalizace nám vrací spíše horší výsledky, jejich porovnáním se zabýváme v experimentální části.

$idf_{ij}$ reprezentuje převrácenou četnost $t_i$ ve všech dokumentech a spočítá se podle vzorce:

\begin{align}
	\begin{split}
		idf_{ij} = \log_2 (\frac{n}{df_i}
	\end{split}					
\end{align}

kde $n$ je celkový počet dokumentů a $df_i$ reprezentuje celkový počet dokumentů obsahujících term $t_i$.

\subsection{Implementace LSI}

Jakmile máme vytvořenou matici vah termů $M_w$, můžeme přistoupit k samotné implementaci LSI. Princip LSI spočívá v tom, že s pomocí \emph{singulárního rozkladu (SVD)} seskupíme tematicky podobné články do jednotlivých k konceptů. Vlivem počtu konceptů na kvalitu výsledků se dále zabýváme v experimentální sekci.

\bigskip 

Singulární rozklad nám matici $M_w$ rozloží následovně:

\begin{align}
	\begin{split}
		M_w = U \cdot S \cdot V^T
	\end{split}					
\end{align}

kde řádky matice $U$ jsou obrazy řádků matice $M_w$, sloupce matice $V$ jsou obrazy sloupců matice $M_w$ a matice $S$ obsahuje na diagonále $M_w$ v sestupném pořadí. Z těchto matic získáme \emph{concept-by-document} matici $M_{cd}$ jako:

\begin{align}
	\begin{split}
		M_{cd} = S \cdot V^T
	\end{split}					
\end{align}

a matici projekce dotazu do prostoru konceptů $M_q$ jako:

\begin{align}
	\begin{split}
		M_q = U^T
	\end{split}					
\end{align}

\subsection{Vyhodnocení dotazu}

Při dotazu na nejpodobnější dokumenty k dokumentu $d_j$ převedeme dotaz do prostoru konceptů na vektor $V_c$ pomocí vzorce:

\begin{align}
	\begin{split}
		V_c = M_{q_{[k,:]}} \cdot M_{w_{:,j}}
	\end{split}					
\end{align}

kde $M_{q_{[k,:]}}$ značí prvních k řádků matice $M_q$ kde k je počet konceptů a $M_{w_{:,j}}$ značí j-tý sloupec matice $M_w$. Nenásobíme tedy celou maticí $M_q$, ale pouze její částí podle počtu konceptů.

\bigskip

Vektor $V_c$ poté pomocí \emph{kosinové podobnosti} porovnáme se sloupcovými vektory matice $M_{{cd}_{[k, :]}}$. Používáme tedy opět jen část matice $M_{cd}$ podle počtu konceptů. Indexy nejpodobnějších sloupcových vektorů matice $M_{{cd}_{[k, :]}}$ pak vrátíme jako indexy nejpodobnějších dokumentů k dokumentu dotazu $d_j$.

\section{Implementace}

Celý projekt jsme programovali v jazyce Python. Práci nám velmi usnadnila jeho knihovna NLTK\footnote{https://www.nltk.org/} nabízející funkce pro práci s přirozeným jazykem. Využili jsme například WordNetLemmatizer pro lemmatizaci či SnowballStemmer pro stemming. Dále jsme v programu hojně využívali Python knihovny pandas\footnote{https://pandas.pydata.org/}  a numpy\footnote{https://numpy.org/}.

\bigskip

Ukládání dat v projektu řešíme přes csv soubory, ke kterým přistupujeme přes pandas funkce. V jednom souboru máme uložené články nad kterými provádíme LSI. V dalších souborech pak máme uložené matice, které nám vzniknou při výpočtech, abychom je mohli cachovat a zrychlili tak běh programu.

\bigskip

Procházení článků vizualizujeme v prohlížeči pomocí Flask\footnote{https://flask.palletsprojects.com/en/1.1.x/} web serveru.

\section{Příklad výstupu}



\section{Experimentální sekce}

\begin{table}[h] % [h] forces the table to be output where it is defined in the code (it suppresses floating)
	\centering % Centre the table
	\begin{tabular}{l l l}
		\toprule
		\textit{Per 50g} & \textbf{Pork} & \textbf{Soy} \\
		\midrule
		Energy & 760kJ & 538kJ\\
		Protein & 7.0g & 9.3g\\
		Carbohydrate & 0.0g & 4.9g\\
		Fat & 16.8g & 9.1g\\
		Sodium & 0.4g & 0.4g\\
		Fibre & 0.0g & 1.4g\\
		\bottomrule
	\end{tabular}
	\caption{Sausage nutrition.}
\end{table}

%------------------------------------------------

\subsection{The table above shows the nutritional consistencies of two sausage types. Explain their relative differences given what you know about daily adult nutritional recommendations.}

Lorem ipsum dolor sit amet, consectetur adipiscing elit. Praesent porttitor arcu luctus, imperdiet urna iaculis, mattis eros. Pellentesque iaculis odio vel nisl ullamcorper, nec faucibus ipsum molestie. Sed dictum nisl non aliquet porttitor. Etiam vulputate arcu dignissim, finibus sem et, viverra nisl. Aenean luctus congue massa, ut laoreet metus ornare in. Nunc fermentum nisi imperdiet lectus tincidunt vestibulum at ac elit. Nulla mattis nisl eu malesuada suscipit.

%----------------------------------------------------------------------------------------
%	CODE LISTING EXAMPLE
%----------------------------------------------------------------------------------------

\section{Diskuze}

\lstinputlisting[
	caption=Luftballons Perl Script., % Caption above the listing
	label=lst:luftballons, % Label for referencing this listing
	language=Perl, % Use Perl functions/syntax highlighting
	frame=single, % Frame around the code listing
	showstringspaces=false, % Don't put marks in string spaces
	numbers=left, % Line numbers on left
	numberstyle=\tiny, % Line numbers styling
	]{luftballons.pl}

%------------------------------------------------

\subsection{How many luftballons will be output by the Listing \ref{lst:luftballons} above?}

Aliquam arcu turpis, ultrices sed luctus ac, vehicula id metus. Morbi eu feugiat velit, et tempus augue. Proin ac mattis tortor. Donec tincidunt, ante rhoncus luctus semper, arcu lorem lobortis justo, nec convallis ante quam quis lectus. Aenean tincidunt sodales massa, et hendrerit tellus mattis ac. Sed non pretium nibh. Donec cursus maximus luctus. Vivamus lobortis eros et massa porta porttitor.

%------------------------------------------------

\subsection{Identify the regular expression in Listing \ref{lst:luftballons} and explain how it relates to the anti-war sentiments found in the rest of the script.}

Fusce varius orci ac magna dapibus porttitor. In tempor leo a neque bibendum sollicitudin. Nulla pretium fermentum nisi, eget sodales magna facilisis eu. Praesent aliquet nulla ut bibendum lacinia. Donec vel mauris vulputate, commodo ligula ut, egestas orci. Suspendisse commodo odio sed hendrerit lobortis. Donec finibus eros erat, vel ornare enim mattis et.

%----------------------------------------------------------------------------------------

\section{Závěr}

\end{document}
